{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgpbmNj9Ra0h6ARx1Z3pBV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TerryTian21/PyTorch-Practice/blob/main/Tutorials/RNN_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNNs\n",
        "\n",
        "Following the tutorial by [Gabriel Loye](https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/) we will explore a practical implementation of RNNs.\n",
        "\n",
        "The goal of this notebook is to create a sentence completion reccommender based on a word or a few characters passed into the network. We will train the model using textual data so it learns the most common \"sequences of words\" enabling it to give us the next most likely words."
      ],
      "metadata": {
        "id": "aNc5vKG45aZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First Implementation\n",
        "\n",
        "To keep this first implementation simple, we will define a few sentences to see how much the model learns. The process goes as follows:\n",
        "1. Creating Vocabulary Dictionaries\n",
        "2. Padding and splitting into input/labels\n",
        "3. One-hot encoding\n",
        "4. Define the Model\n",
        "5. Train Model\n",
        "6. Evaluate Model"
      ],
      "metadata": {
        "id": "p4alqATp93G_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "rvr1-9ey_NtU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Vocab Dictionaries"
      ],
      "metadata": {
        "id": "hJG4XK7A_Unq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [ \"hey how are you\",\n",
        "        \"good I am fine\",\n",
        "         \"have a nice day\",\n",
        "         \"the weather is good today\",\n",
        "         \"how was your weekend\",\n",
        "         \"It was great, thank you\"]"
      ],
      "metadata": {
        "id": "VjW-ER12_a84"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join all the sentences together and extract unique characters from combined sentences\n",
        "\n",
        "chars = set(\"\".join(text))\n",
        "print(chars)\n",
        "\n",
        "int2char = dict(enumerate(chars))\n",
        "print(int2char)\n",
        "\n",
        "# Dict that maps chars to ints\n",
        "char2int = {char: val for val, char in int2char.items()}\n",
        "print(char2int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vl6RomC_pMO",
        "outputId": "b6547263-922c-4963-df41-3abfa1ad87a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'t', 'v', 'f', 's', ',', ' ', 'y', 'i', 'c', 'o', 'u', 'a', 'I', 'd', 'k', 'g', 'h', 'r', 'e', 'n', 'w', 'm'}\n",
            "{0: 't', 1: 'v', 2: 'f', 3: 's', 4: ',', 5: ' ', 6: 'y', 7: 'i', 8: 'c', 9: 'o', 10: 'u', 11: 'a', 12: 'I', 13: 'd', 14: 'k', 15: 'g', 16: 'h', 17: 'r', 18: 'e', 19: 'n', 20: 'w', 21: 'm'}\n",
            "{'t': 0, 'v': 1, 'f': 2, 's': 3, ',': 4, ' ': 5, 'y': 6, 'i': 7, 'c': 8, 'o': 9, 'u': 10, 'a': 11, 'I': 12, 'd': 13, 'k': 14, 'g': 15, 'h': 16, 'r': 17, 'e': 18, 'n': 19, 'w': 20, 'm': 21}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The char2int library : holds all the letters/symbols that were present in our sentences and maps them to a unique integer"
      ],
      "metadata": {
        "id": "JiWwK-_pAEjA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding Input Sentences\n",
        "\n",
        "Typically RNNs are able to take variable sized inputs we usually want to feed the input in batches to speed up training. In order to be used as batches the inputs (sequences) are the same length.\n",
        "\n",
        "<br>\n",
        "\n",
        "In our case : we will be padding shorter sentences with spaces to match the length of the longest sentences."
      ],
      "metadata": {
        "id": "wHzT1oUGAS0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find max length of longest string\n",
        "\n",
        "maxlen = max([len(input.split(\" \")) for input in text])\n",
        "print(maxlen)\n",
        "\n",
        "# Padd sentences until sentences matches length of longest sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6lSAoGQAWVZ",
        "outputId": "44a7fadc-a01b-4587-ed81-6a05385d3d64"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    }
  ]
}